# Introduction
This project aims at implementing several convolution kernels for a CNN Inferencing Engine, analyzing the algorithms for AlexNet and VGG-19 architectures and picking the most efficient out of the implemented ones for those architectures. The following tasks were implemented in the project:
* Creating a custom specification format which can be used to store and load available pretrained models in C++. Converting pretrained VGG-19 and AlexNet to the developed format 
* Implementing the various convolution algorithms without the help of CUDNN library:
	* Direct Convolution
	* Convolution that uses IM2COL unrolling and GEMM 
	* Convolution that uses FFT computation
	* Convolution that uses Winograd Algorithm
* Implementing a forward pass library which can read the custom model and perform standard operations like Convolution (using both CUDNN and the above implemented functions), Pooling, Activation and FC/Linear Layer operation. 
* Creating a small dataset to test the correctness of the above operations and algorithms
* Profiling the convolution algorithms for the above mentioned architectures for run times and GPU memory usage

# Overview of Implementation
The following diagram represents an overview of our system:
![enter image description here](https://lh3.googleusercontent.com/9LWB_M5iMdUYu774jumzN5LKlGgXu3RFYyGyBC8zNf2mhxfGqQBL4frUN1OEs30lvcoIXnjhcfpt1uUs8E3hEtpB8KrZCrfTgBCHCUs2fYSGzC--f3HfCOpLKwfzoAv6R34aEuuJ8dgSSaOKFdeA9-BgsMFqAg-Ivo8EkBCOnT8AQpng0i4KfxBcOdvMIByVY27noEjQ5BZ8zSTnpc5pgg0wf9pDmwyH4lCAnxkdbeiWGMpVY65rCTptYgxavxqXe0LeHVxi34NgTys6fUuB9aI_I-vrfyS1iRaO7epW2MrxI6KA_wHdumprNFdihm_vhqQb5TTmnyaixK-DA6vNwupVsWGCx-dw_OdYXMg9PmCzfp1Tjlg5XQUM97PZFf50Zl_PK3DUytTl-QYz9mz68oFvFQrV78Iyuk1E6TcvyM7BTdSBxR7c056IUDWu4phNtDJIHWBPOZNstUsD6KzJY7WFwBACMgEUZjsvYA76ZbHVsp_x3Uu-XghefIUn6hxSEAN476BT13OdlbYJPa6zgWevOYX7bT6Nc5yKxSbzl3eBcD7mBpg2Rl5ao2Z9KMCsRbalWP9MPW27LJQaatZ4iLYkcFnw0dpMraC-UdmjwjGnskQQGd1QSkmpPzwESpqb8oA0jc9zTH4_fkWtMunTOyVzOpvbFMWgN5_e2aSGat6R7pZrzmDr-ZH8eXDjE8Y=w1315-h930-no)
  
# Directory Structure
Here, we briefly explain the skeleton directory structure of the project. The concrete implementation details of the various components shown in the diagram above are present within the respective directories:
```
.
├── forward/				  : Contains the main Inferencing Engine libraries 
│   ├── data/					: Contains the dataset
│   ├── batch_test/				: Contains the Batch Image CNN Forward Test files
│   ├── cnn_forward_test/		: Contains the Single Image CNN Forward Test files
│   ├── operations_test/		: Contains the Batch Image CNN Forward Test files
│   ├── cnn_forward.h			: Library that wraps the forward pass and model loading
│   ├── cnn_forward.cc		
│   ├── data_util.h				: Data Loader Library
│   ├── data_util.cc
│   ├── operations.h			: Library containing the main CNN operations
│  	└── operations.cc 
├── kernels/				  : Contains Kernel Implementations
│   ├── Direct/					: Contains the implementation of Direct Convolution
│   ├── FFT/					: Contains the implementation of the FFT based Convolution
│   ├── im2col/					: Contains the implementation of the Im2Col unrolling and GEMM based Convolution
│   └── winograd/				: Contains the implementation of the Winograd-based Convolution
├── pretrained-models/		  : Directory where the pretrained VGG and AlexNet modes are saved
├── profiling/				  : Contains the code for profiling
│   ├── MemoryUsageProfiling/ 	: Contains the code for Memory Usage profiling
│   └── TimeProfiling/			: Contains the code for Kernel Run Time profiling 
├── proto					  : Contains files related to protobuf
│   ├── * Protobuf				: The files generated by protobuf compiler for
│	│	generated files *		  C++ and Python
│   ├── network.proto			: Custom Protobuf Specification file for a CNN model 
│   ├── translator.h			: Library that translates protobuf objects to operations in forward/operations.h class 
│   └── translator.cc
├── Makefile				  : Global Makefile
├── ConvertToSpecification.py : Script to download pretrained models and save them according to the custom specification 
└── README.md
```
# Requirements
To run the entire code, there are a few requirements :
* CUDA 10.1 (This is the version  tested on. To change it some makefiles have to changed)
* CUDNN  
* Google Protobuf Complier and C++ Runtime :
* PyTorch 
* OpenCV (C++ and Python)

# Getting Started : Pre-Build Steps
After cloning the directory, there are certain steps that need to be carried out so that the code can be compiled and executed

**NOTE:** Even though we recommend carrying out the steps manually,  the global Makefile (in the main directory) now supports doing all steps mentioned below for you by running:
```
$ make ready_project
```

###  1. Compiling the proto files
Since every version of protobuf present has some differences specially in the C++ runtime, it is important to build C++ libraries again from the specification:
```
# In the main directory #
$ cd proto
$ protoc -I=. --cpp_out=. ./network.proto
```
Additionally, if you encounter problems with the proto files generated for python (it is more stable across versions than C++ files but it might change in the future), you should compile those as well: 
``` (In the proto directory) $ protoc -I=. --python_out=. ./network.proto ```
### 2. Downloading the pretrained models and saving them
```
# In the main directory #
$ python ConvertToSpecification.py
```
### 3. Unzipping the Training Data
```
# In the main directory #
$ cd forward/data
$ unzip MiniImageNet.zip
```

# Compile Instructions

### Test-1 Operations Test

Located under forward/opearations_test:

* Tests the individual component operations in the operations.h library and compares the results with Pytorch Output

* Compile - `make test`

* Run the test for direct convolution - `make run_direct`

* Run the test for FFT-based convolution - `make run_fft`

* Run the test for Winograd-based convolution - `make run_winograd`

* Run the test for im2col-based convolution - `make run_im2col`

* Clean the test directory - `make clean`

* Requirements - OpenCV, Pytorch10.1
  

### Setup Protobuf

```shell

$ apt-get install autoconf automake libtool curl make g++ unzip

$ git clone https://github.com/protocolbuffers/protobuf.git

$ cd protobuf

$ git submodule update --init --recursive

$ ./autogen.sh

$ ./configure

$ make -j8

$ make check

$ sudo make install

$ sudo ldconfig

$ cd ..

```

  

#### Test-2 CNN Forward Test

Located under forward/cnn_forward_test:

* Tests the CNN Forward library by running both VGG19 and Alexnet on a single image and comparing the results with Pytorch Output

* Compile - `make test`

* Run the test for direct convolution - `make run_direct`

* Run the test for FFT-based convolution - `make run_fft`

* Run the test for Winograd-based convolution - `make run_winograd`

* Run the test for im2col-based convolution - `make run_im2col`

* Clean the test directory - `make clean`

* Requirements -

  

## Using MiniImageNet Data

We have created a custom dataset from ImageNet with 372 images and resized them to 256X256. To use the dataset and run the batch tests, extract the zip - MiniImageNet.zip present in forward/data folder first

  

```

$ cd forward/data/MiniImageNet.zip

$ unzip MiniImageNet.zip

$ cd ..

```

  

#### Test-3 Batch Test

Located under forward/batch_test:

* Tests the CNN Forward library for a batch of 8 images by running both VGG19 and Alexnet and comparing the results with Pytorch Output

* Compile - `make test`

* Run the test for direct convolution - `make run_direct`

* Run the test for FFT-based convolution - `make run_fft`

* Run the test for Winograd-based convolution - `make run_winograd`

* Run the test for im2col-based convolution - `make run_im2col`

* Clean the test directory - `make clean`

* Requirements -

  

##### Notebook to run the tests on Google Colab - https://colab.research.google.com/drive/1GD7mgy3pVIKSnobhY7hSdD_3P9i5532R