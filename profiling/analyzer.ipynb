{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns   \n",
    "sns.set(context = \"poster\", font_scale = 0.95, rc={\"lines.linewidth\": 1.5, 'lines.markersize': 10, 'legend.frameon': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_DIR = \"./Plots/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALEX_NET_LOG = \"./logALEX.txt\"\n",
    "VGG_NET_LOG = \"./logVGG.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hard Coded #\n",
    "def getAlexNetSpecification():\n",
    "    # (input channels, output channels, kernel size, stride, padding)\n",
    "    kernel_specifications = [(3, 64, 11, 4, 2), (64, 192, 5, 1, 2), (192, 384, 3, 1, 1), (384, 256, 3, 1, 1), (256, 256, 3, 1, 1)]\n",
    "    output_specifications = [(1, 64, 63, 63), (1, 192, 31, 31), (1, 384, 15, 15), (1, 256, 15, 15), (1, 256, 15, 15)]\n",
    "    return kernel_specifications, output_specifications\n",
    "\n",
    "def getVGGSpecification():\n",
    "    kernel_specifications = [(3, 64, 3, 1, 1), (64, 64, 3, 1, 1), (64, 128, 3, 1, 1), (128, 128, 3, 1, 1), (128, 256, 3, 1, 1), (256, 256, 3, 1, 1), (256, 256, 3, 1, 1), (256, 256, 3, 1, 1), (256, 512, 3, 1, 1), (512, 512, 3, 1, 1), (512, 512, 3, 1, 1), (512, 512, 3, 1, 1), (512, 512, 3, 1, 1), (512, 512, 3, 1, 1), (512, 512, 3, 1, 1), (512, 512, 3, 1, 1)]\n",
    "    output_specifications = [(1, 64, 256, 256), (1, 64, 256, 256), (1, 128, 128, 128), (1, 128, 128, 128), (1, 256, 64, 64), (1, 256, 64, 64), (1, 256, 64, 64), (1, 256, 64, 64), (1, 512, 32, 32), (1, 512, 32, 32), (1, 512, 32, 32), (1, 512, 32, 32), (1, 512, 16, 16), (1, 512, 16, 16), (1, 512, 16, 16), (1, 512, 16, 16)]\n",
    "    return kernel_specifications, output_specifications\n",
    "\n",
    "def getLayerParams(filter_spec, input_dimensions):\n",
    "    number_of_Paremeters = filter_spec[0]*filter_spec[1]*(filter_spec[2]**2)\n",
    "    number_of_InputValues = 1\n",
    "    for d in input_dimensions:\n",
    "        number_of_InputValues *= d\n",
    "    return number_of_Paremeters, number_of_InputValues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadAlexLog():\n",
    "    input_spec = [(1,3,256,256)]\n",
    "    kernel_spec, output_spec = getAlexNetSpecification()\n",
    "    input_spec.extend(output_spec[:-1])\n",
    "        \n",
    "    layer_specification_dict = {}\n",
    "        \n",
    "    alex_header = [\"ALGO\", \"BATCHSIZE\", \"TIME_TYPE\" ]\n",
    "    for i,k in enumerate(kernel_spec):\n",
    "        header_ = \"CONV\"+str(i)\n",
    "        \n",
    "        layer_specification_dict[header_] = {}\n",
    "        layer_specification_dict[header_]['input'] = input_spec[i]\n",
    "        layer_specification_dict[header_]['filter'] = k\n",
    "        layer_specification_dict[header_]['output'] = output_spec[i]\n",
    "\n",
    "        alex_header.append(header_)\n",
    "    \n",
    "    data = pd.read_csv(ALEX_NET_LOG, header=None, names = alex_header) \n",
    "    return alex_header, data, layer_specification_dict\n",
    "\n",
    "def loadVGGLog():\n",
    "    input_spec = [(1,3,256,256)]\n",
    "    kernel_spec, output_spec = getVGGSpecification()\n",
    "    input_spec.extend(output_spec[:-1])\n",
    "        \n",
    "    layer_specification_dict = {}\n",
    "        \n",
    "    vgg_header = [\"ALGO\", \"BATCHSIZE\", \"TIME_TYPE\" ]\n",
    "    for i,k in enumerate(kernel_spec):\n",
    "        header_ = \"CONV\"+str(i)\n",
    "        \n",
    "        layer_specification_dict[header_] = {}\n",
    "        layer_specification_dict[header_]['input'] = input_spec[i]\n",
    "        layer_specification_dict[header_]['filter'] = k\n",
    "        layer_specification_dict[header_]['output'] = output_spec[i]\n",
    "\n",
    "        vgg_header.append(header_)\n",
    "    \n",
    "    data = pd.read_csv(VGG_NET_LOG, header=None, names = vgg_header) \n",
    "    return vgg_header, data, layer_specification_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer Wise Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLayerWiseDataForTimeType(data, layer_cols, layer_specification_dict, batch_size, architecture, plot_path, time_type = ' CONV', label_y = 'Convolution Time (in ms)', plot_title = 'Convolution Time across Layers'):\n",
    "    data_batch = data.loc[data['BATCHSIZE'] == batch_size].copy()\n",
    "    data_frame_tt = data_batch.loc[data_batch['TIME_TYPE'] == time_type].copy()\n",
    "    data__frame_tt_transposed = data_frame_tt.set_index('ALGO')[layer_cols].T\n",
    "    data__frame_tt_transposed['Layers'] = data__frame_tt_transposed.index\n",
    "    df_to_plot = data__frame_tt_transposed.melt('Layers', value_name='Time')\n",
    "    \n",
    "    X_ = []\n",
    "    for i,row in df_to_plot.iterrows():\n",
    "        num_filter_parameters, num_input_values = getLayerParams(layer_specification_dict[row['Layers']]['filter'],layer_specification_dict[row['Layers']]['input'])\n",
    "        label =  row['Layers'] + \"\\n\" + str(layer_specification_dict[row['Layers']]['filter']) + \"\\n\" + \"#P = \" +str(num_filter_parameters) + \"\\n\" + \"IS = \" + str(num_input_values) + \"x\" +str(batch_size)+\"\\n\"\n",
    "        X_.append(label)\n",
    "\n",
    "    df_to_plot['X_LABELS'] = X_\n",
    "    \n",
    "    plt.figure(figsize=(max(16, len(layer_cols)*2+4),8)) # this creates a figure 8 inch wide, 4 inch high\n",
    "    \n",
    "    ax = sns.lineplot(x='X_LABELS', y='Time', hue='ALGO', marker = 'o', data=df_to_plot, sort=False)\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set(xlabel='Convolution Layers', ylabel = label_y)\n",
    "    ax.tick_params(axis=\"x\", labelsize = 13)\n",
    "    ax.set_title(plot_title + \" for Batchsize = \" + str(batch_size), y=1.15)\n",
    "    box = ax.get_position()\n",
    "    \n",
    "    ax.set_position([box.x0, box.y0, box.width , box.height * 0.95]) # resize position\n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles=handles[1:], labels=labels[1:],bbox_to_anchor=(0.5, 1.1), loc='upper center' , borderaxespad=0., ncol = len(layer_cols)-1)\n",
    "    \n",
    "    for i,row in df_to_plot.iterrows():\n",
    "        x = row['X_LABELS']\n",
    "        y = row['Time']\n",
    "        ax.text(x,y,f'{y:.2f}\\n',ha = 'center', va = 'center', clip_on=True, fontsize = 18)\n",
    "    plt.savefig(plot_path+\"LayerWise_\"+architecture+time_type.strip()+'_'+str(batch_size)+'.png', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LayerWiseAnalysis(data, header, layer_specification_dict, architecture):\n",
    "    layer_cols = header[3:]\n",
    "    \n",
    "    plot_dir_path = PLOT_DIR + architecture + \"/\"\n",
    "    if not os.path.isdir(plot_dir_path):\n",
    "        os.mkdir(plot_dir_path)\n",
    "    \n",
    "    time_types = [' CONV', ' OVERHEAD', ' TOTAL']\n",
    "    y_labels = ['Convolution Time (in ms)', 'Overhead Time (in ms)', 'Total Time (in ms)']\n",
    "    plot_titles = ['Convolution Time across Layers', 'Overhead Time across Layers', 'Total Time across Layers [Includes the extra overheads] ']\n",
    "    for i,t in enumerate(time_types):\n",
    "        plotLayerWiseDataForTimeType(data, layer_cols, layer_specification_dict, batch_size = 1, architecture = architecture, plot_path = plot_dir_path, time_type = t, label_y = y_labels[i], plot_title = plot_titles[i])\n",
    "        plotLayerWiseDataForTimeType(data, layer_cols, layer_specification_dict, batch_size = 8, architecture = architecture, plot_path = plot_dir_path, time_type = t, label_y = y_labels[i], plot_title = plot_titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "header, data, layer_specification_dict = loadVGGLog()\n",
    "LayerWiseAnalysis(data, header, layer_specification_dict, \"VGG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prajwal/anaconda3/lib/python3.7/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    }
   ],
   "source": [
    "header, data, layer_specification_dict = loadAlexLog()\n",
    "LayerWiseAnalysis(data, header, layer_specification_dict, \"ALEX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batchwise Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchWisePlot(data, layer_cols, layer_specification_dict, architecture, plot_path, time_type = ' CONV', label_y = 'Sum of Convolution Time (in ms)', plot_title = 'Sum of Convolution Time Vs Batchsize'):\n",
    "    data_batchwise = data.loc[data['TIME_TYPE'] == time_type].copy()\n",
    "    data_batchwise['SUM'] = data_batchwise[layer_cols].sum(axis = 1)\n",
    "    \n",
    "    plt.figure(figsize=(14,10)) # this creates a figure 8 inch wide, 4 inch high\n",
    "    ax = sns.lineplot(x='BATCHSIZE', y='SUM', hue='ALGO', marker = 'o', data=data_batchwise, sort=False)\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set(xlabel='Batch Size', ylabel = label_y)\n",
    "    ax.tick_params(axis=\"x\", labelsize = 13)\n",
    "    ax.set_title(plot_title, y=1.15)\n",
    "    box = ax.get_position()\n",
    "\n",
    "    ax.set_position([box.x0, box.y0, box.width , box.height * 0.95]) # resize position\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles=handles[1:], labels=labels[1:],bbox_to_anchor=(0.5, 1.1), loc='upper center' , borderaxespad=0., ncol = len(layer_cols)-1)\n",
    "\n",
    "    for i,row in data_batchwise.iterrows():\n",
    "        x = row['BATCHSIZE']\n",
    "        y = row['SUM']\n",
    "        ax.text(x,y,f'{y:.2f}\\n',ha = 'center', va = 'center', clip_on=True, fontsize = 14)\n",
    "    plt.savefig(plot_path+\"BatchWise_\"+architecture+time_type.strip()+'.png', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BatchWiseAnalysis(data, header, layer_specification_dict, architecture):\n",
    "    layer_cols = header[3:]\n",
    "    \n",
    "    plot_dir_path = PLOT_DIR + architecture + \"/\"\n",
    "    if not os.path.isdir(plot_dir_path):\n",
    "        os.mkdir(plot_dir_path)\n",
    "\n",
    "    time_types = [' CONV', ' OVERHEAD', ' TOTAL']\n",
    "    y_labels = ['Sum of Convolution Time (in ms)', 'Sum of Overhead Time (in ms)', 'Sum of Total Time (in ms)']\n",
    "    plot_titles = ['Sum of Convolution Time Vs Batchsize', 'Sum of Overhead Time Vs Batchsize', 'Sume of Total Time [Includes the extra overheads] Vs Batchsize']\n",
    "    for i,t in enumerate(time_types):\n",
    "        batchWisePlot(data, layer_cols, layer_specification_dict, architecture = architecture, plot_path = plot_dir_path, time_type = t, label_y = y_labels[i], plot_title = plot_titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "header, data, layer_specification_dict = loadVGGLog()\n",
    "BatchWiseAnalysis(data, header, layer_specification_dict, \"VGG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "header, data, layer_specification_dict = loadAlexLog()\n",
    "BatchWiseAnalysis(data, header, layer_specification_dict, \"ALEX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
